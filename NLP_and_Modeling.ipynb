{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP and GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section will demonstrate how data was cleaned (tokenized, lemmatized, etc) and how the best model is chosen. The models tested here are Logistic Regression and Multinomial Naive Bayes, along with testing to compare performance between using CountVectorizer and TFIDFVectorizer on this dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import regex as re\n",
    "import time \n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function for calculating run time of GridSearching \n",
    "# some of these really took a while \n",
    "\n",
    "def run(start, end): \n",
    "    long = end - start \n",
    "    minutes = int(long // 60 )\n",
    "    seconds = int(round(long - 60 * minutes))\n",
    "    return f\"{minutes}m {seconds}s\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \"Cleaning\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many reddit posts can have special characters and emojis, along with some links. These are two very text-heavy subreddits, so there should not be much pollution by external links or images, however to remove links that may be present I will target strings that contain \"www.\" or \"https:\" and remove only those elements, but keep the rest of the string if anything else remains. The data will also be lemmatized at this stage. \"Cleaning\" is in quotes here because some of the modeling below will involve either including or excluding stopwords, which could be considered another form of cleaning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./datasets/combined_raw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null values with \" \"\n",
    "# not filling with symbol (since it will be scrubbed later), or word since this could pollute the data \n",
    "df.fillna(\" \", inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, get rid of links\n",
    "# target text that has \"www.\" or \"https:\"\n",
    "\n",
    "# scrubbing links from titles\n",
    "\n",
    "for title in df[\"title\"]: \n",
    "    # convert title to lowercase \n",
    "    lower_title = title.lower()\n",
    "    \n",
    "    # split title into individual words\n",
    "    title_tokens = lower_title.split()\n",
    "    \n",
    "    # loop through each title searching for links, remove links ONLY\n",
    "    for token in title_tokens: \n",
    "        if \"www.\" in token: \n",
    "            title_tokens.remove(token)\n",
    "        elif \"http://\" in token: \n",
    "            title_tokens.remove(token)\n",
    "        elif \"https://\" in token: \n",
    "            title_tokens.remove(token)\n",
    "            \n",
    "    # combined processed words back into one string\n",
    "    processed_title = \" \".join(title_tokens)\n",
    "    \n",
    "    # replace old title with processed title\n",
    "    df[\"title\"].replace(to_replace = title, value = processed_title, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# same thing is done for body text of posts \n",
    "\n",
    "for body in df[\"selftext\"]: \n",
    "    \n",
    "    lower_body = body.lower()\n",
    "    body_tokens = lower_body.split()\n",
    "    \n",
    "    for token in body_tokens: \n",
    "        if \"www.\" in token: \n",
    "            body_tokens.remove(token)\n",
    "        elif \"http://\" in token: \n",
    "            body_tokens.remove(token)\n",
    "        elif \"https://\" in token: \n",
    "            body_tokens.remove(token)\n",
    "            \n",
    "    processed_body = \" \".join(body_tokens)\n",
    "    df[\"selftext\"].replace(to_replace = body, value = processed_body, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next, remove special (in this case, non-letter) characters \n",
    "# combine this step with lemmatizing \n",
    "\n",
    "tokenizer = RegexpTokenizer(\"\\w+\")\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "for body in df[\"selftext\"]: \n",
    "    words = tokenizer.tokenize(body)\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in words]\n",
    "    processed = \" \".join(lemmatized)\n",
    "    df[\"selftext\"].replace(to_replace = body, value = processed, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for title in df[\"title\"]: \n",
    "    words = tokenizer.tokenize(title)\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in words]\n",
    "    processed = \" \".join(lemmatized)\n",
    "    df[\"title\"].replace(to_replace = title, value = processed, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After some brainstorming with our Merciful Overloard Charlie, combining the text from both the title and selftext into one column seemed like a great idea to organize the text for modeling. I don't really want to go back and do it from the beginning and then have to re-write cleaning for the one column right now, so I'm just going to create a new column using the two cleaned columns. I'll fix this when I have some more time for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"title\"] + \" \" + df[\"selftext\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2069, 14470)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# out of curiosity let's CountVectorize the text column \n",
    "\n",
    "cvec = CountVectorizer()\n",
    "\n",
    "curiosity = cvec.fit_transform(df[\"text\"])\n",
    "\n",
    "curiosity.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# holy moly, 14,466 distinct words and that is without including word combinations! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.535524\n",
       "1    0.464476\n",
       "Name: abusive_relationship, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"abusive_relationship\"].value_counts(normalize = True)\n",
    "\n",
    "# close to equal distribution of abusive relationship occurrences, no need to stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[\"text\"]\n",
    "\n",
    "y = df[\"abusive_relationship\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 42, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(X_train, y_train, left_index = True, right_index = True)\n",
    "\n",
    "test = pd.merge(X_test, y_test, left_index = True, right_index = True)\n",
    "\n",
    "train.to_csv(\"./datasets/train.csv\", index = False)\n",
    "test.to_csv(\"./datasets/test.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section explores the best way to model this data using either CountVectorizer or TFIDFVectorizer in combination with either a Logistic Regression model or a Multinomial Naive Bayes model. I use GridSearchCV to test a range of values for hyperparameters for each model to determine the best configuration. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters \n",
    "\n",
    "| Parameter | Options | Purpose | \n",
    "|:--- | :-- |:---|\n",
    "| ngram range | (1, 1), (1, 2), (1, 3) | Determines whether words used will be single words, single words and word pairings, or single words, word pairings, and 3-word sets\n",
    "| stop words | None, \"english\" | Specifies whether to remove stop words from dataset or not | \n",
    "| max features | 100, 300, 500, 700, 900 | Determines number of words used in model | \n",
    "| min df | 0.1, 0.2, 0.3 | Specifies the minimum proportion of documents a word must appear in for it to be part of the model | \n",
    "| max df | 0.6, 0.7, 0.8, 0.9 | Determines the maximum proportion of documents a word must appear in for it to be part of the model | "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Functions and Hyperparameter Sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I tried running all of the different hyperparameters all at once, it took a ridiculous length of time. Instead, I decided to break it up into a few different sets of hyperparameters, define a function to GridSearch with every hyperparameter set, and then print out statistics from each fitting. I also created a dictionary to put the model statistics in to turn into a DataFrame for more clear visualization of which models with which hyperparameters performed best. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer hyperparameters involving ngram, stop word removal, and feature numbers\n",
    "vec_params_features = {\n",
    "    \"vec__ngram_range\": [(1, 1), (1, 2), (1, 3)], \n",
    "    \"vec__stop_words\": [None, \"english\"], \n",
    "    \"vec__max_features\": [100, 300, 500, 700, 900]}\n",
    "\n",
    "# vectorizer hyperparameters involving ngram, stop word removal, min document appearance, and max document appearance\n",
    "vec_params_dfs = {\n",
    "    \"vec__ngram_range\": [(1, 1), (1, 2), (1, 3)], \n",
    "    \"vec__stop_words\": [None, \"english\"], \n",
    "    \"vec__min_df\": [0.1, 0.2, 0.3], \n",
    "    \"vec__max_df\": [0.6, 0.7, 0.8, 0.9]\n",
    "}\n",
    "\n",
    "# vectorizer hyperparameters involving all hyperparameters as above, though with more limited options \n",
    "vec_params_all = {\n",
    "    \"vec__ngram_range\": [(1, 1), (1, 2)], \n",
    "    \"vec__stop_words\": [None, \"english\"], \n",
    "    \"vec__min_df\": [0.1, 0.2], \n",
    "    \"vec__max_df\": [0.7, 0.8], \n",
    "    \"vec__max_features\": [300, 500, 700]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary to store model metrics in \n",
    "# will be transformed to DataFrame at end for easy visualization of performance differences\n",
    "model_outcomes = {\"Transformer\": [], \n",
    "                  \"Estimator\": [], \n",
    "                  \"Parameters\": [],\n",
    "                  \"Best Parameters\": [], \n",
    "                  \"Best Score\": [], \n",
    "                  \"Training Score\": [], \n",
    "                  \"Test Score\": [], \n",
    "                  \"Discrepancy\": [], \n",
    "                  \"Runtime\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict = {\"df_params\": vec_params_dfs, \"features_params\": vec_params_features, \n",
    "              \"limited_all_params\": vec_params_all}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gridsearch_batch(vectorizer, classifier, parameter_dict, outcomes_dict): \n",
    "    parameter_names = list(param_dict.keys())\n",
    "    \n",
    "    cycle = 0\n",
    "    \n",
    "    time_total = 0 \n",
    "    for i in param_dict:\n",
    "        pipe = Pipeline([\n",
    "            (\"vec\", vectorizer), \n",
    "            (\"class\", classifier)\n",
    "        ])\n",
    "        \n",
    "        grid = GridSearchCV(pipe, parameter_dict[i], cv = 5)\n",
    "        \n",
    "        start = time.time() \n",
    "        grid.fit(X_train, y_train)\n",
    "        end = time.time()\n",
    "        \n",
    "        train = grid.score(X_train, y_train)\n",
    "        test = grid.score(X_test, y_test)\n",
    "        \n",
    "        print(f\"Model with {parameter_names[cycle]} took {run(start, end)} to run.\")\n",
    "        print(f\"Best parameters: \\n{grid.best_params_}\")\n",
    "        print(f\"Best score: {grid.best_score_}\")\n",
    "        print(f\"Training score: {train}\")\n",
    "        print(f\"Test score: {test}\")\n",
    "        \n",
    "        fill = [f\"{vectorizer}\", f\"{classifier}\", parameter_names[cycle], grid.best_params_, grid.best_score_, \n",
    "                train, test, (train - test), run(start, end)]\n",
    "        \n",
    "        count = 0\n",
    "        for field in outcomes_dict: \n",
    "            outcomes_dict[field].append(fill[count])\n",
    "            count += 1\n",
    "        \n",
    "        print(\"----------\")\n",
    "        \n",
    "        cycle += 1\n",
    "        time_total += (end - start)\n",
    "    print(f\"This entire process took {run(0, time_total)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TFIDFVectorizer and Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with df_params took 9m 26s to run.\n",
      "Best parameters: \n",
      "{'vec__max_df': 0.6, 'vec__min_df': 0.1, 'vec__ngram_range': (1, 2), 'vec__stop_words': 'english'}\n",
      "Best score: 0.9033149171270718\n",
      "Training score: 0.9330110497237569\n",
      "Test score: 0.9114331723027376\n",
      "----------\n",
      "Model with features_params took 3m 55s to run.\n",
      "Best parameters: \n",
      "{'vec__max_features': 300, 'vec__ngram_range': (1, 2), 'vec__stop_words': 'english'}\n",
      "Best score: 0.914364640883978\n",
      "Training score: 0.93853591160221\n",
      "Test score: 0.9162640901771336\n",
      "----------\n",
      "Model with limited_all_params took 3m 22s to run.\n",
      "Best parameters: \n",
      "{'vec__max_df': 0.7, 'vec__max_features': 300, 'vec__min_df': 0.1, 'vec__ngram_range': (1, 2), 'vec__stop_words': 'english'}\n",
      "Best score: 0.9033149171270718\n",
      "Training score: 0.9343922651933702\n",
      "Test score: 0.9146537842190016\n",
      "----------\n",
      "This entire process took 16m 44s\n"
     ]
    }
   ],
   "source": [
    "gridsearch_batch(TfidfVectorizer(), LogisticRegression(solver = \"liblinear\"), param_dict, model_outcomes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TFIDFVectorizer and Multinomial Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with df_params took 8m 59s to run.\n",
      "Best parameters: \n",
      "{'vec__max_df': 0.6, 'vec__min_df': 0.1, 'vec__ngram_range': (1, 2), 'vec__stop_words': None}\n",
      "Best score: 0.8611878453038674\n",
      "Training score: 0.8839779005524862\n",
      "Test score: 0.8486312399355878\n",
      "----------\n",
      "Model with features_params took 3m 27s to run.\n",
      "Best parameters: \n",
      "{'vec__max_features': 900, 'vec__ngram_range': (1, 3), 'vec__stop_words': 'english'}\n",
      "Best score: 0.8825966850828729\n",
      "Training score: 0.9164364640883977\n",
      "Test score: 0.8904991948470209\n",
      "----------\n",
      "Model with limited_all_params took 3m 0s to run.\n",
      "Best parameters: \n",
      "{'vec__max_df': 0.7, 'vec__max_features': 700, 'vec__min_df': 0.1, 'vec__ngram_range': (1, 2), 'vec__stop_words': None}\n",
      "Best score: 0.8577348066298343\n",
      "Training score: 0.8832872928176796\n",
      "Test score: 0.8502415458937198\n",
      "----------\n",
      "This entire process took 15m 26s\n"
     ]
    }
   ],
   "source": [
    "gridsearch_batch(TfidfVectorizer(), MultinomialNB(), param_dict, model_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CountVectorizer and Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with df_params took 9m 19s to run.\n",
      "Best parameters: \n",
      "{'vec__max_df': 0.6, 'vec__min_df': 0.1, 'vec__ngram_range': (1, 1), 'vec__stop_words': 'english'}\n",
      "Best score: 0.9468232044198895\n",
      "Training score: 0.9854972375690608\n",
      "Test score: 0.9436392914653784\n",
      "----------\n",
      "Model with features_params took 4m 3s to run.\n",
      "Best parameters: \n",
      "{'vec__max_features': 500, 'vec__ngram_range': (1, 2), 'vec__stop_words': 'english'}\n",
      "Best score: 0.9433701657458563\n",
      "Training score: 0.9903314917127072\n",
      "Test score: 0.9484702093397746\n",
      "----------\n",
      "Model with limited_all_params took 3m 26s to run.\n",
      "Best parameters: \n",
      "{'vec__max_df': 0.8, 'vec__max_features': 300, 'vec__min_df': 0.1, 'vec__ngram_range': (1, 1), 'vec__stop_words': 'english'}\n",
      "Best score: 0.9412983425414365\n",
      "Training score: 0.9861878453038674\n",
      "Test score: 0.9404186795491143\n",
      "----------\n",
      "This entire process took 16m 49s\n"
     ]
    }
   ],
   "source": [
    "gridsearch_batch(CountVectorizer(), LogisticRegression(solver = \"liblinear\"), param_dict, model_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### CountVectorizer and Multinomial Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with df_params took 8m 59s to run.\n",
      "Best parameters: \n",
      "{'vec__max_df': 0.6, 'vec__min_df': 0.1, 'vec__ngram_range': (1, 2), 'vec__stop_words': 'english'}\n",
      "Best score: 0.888121546961326\n",
      "Training score: 0.893646408839779\n",
      "Test score: 0.8840579710144928\n",
      "----------\n",
      "Model with features_params took 3m 46s to run.\n",
      "Best parameters: \n",
      "{'vec__max_features': 900, 'vec__ngram_range': (1, 1), 'vec__stop_words': 'english'}\n",
      "Best score: 0.9019337016574586\n",
      "Training score: 0.9247237569060773\n",
      "Test score: 0.9066022544283414\n",
      "----------\n",
      "Model with limited_all_params took 3m 3s to run.\n",
      "Best parameters: \n",
      "{'vec__max_df': 0.7, 'vec__max_features': 300, 'vec__min_df': 0.1, 'vec__ngram_range': (1, 2), 'vec__stop_words': 'english'}\n",
      "Best score: 0.8846685082872928\n",
      "Training score: 0.8957182320441989\n",
      "Test score: 0.8872785829307569\n",
      "----------\n",
      "This entire process took 15m 48s\n"
     ]
    }
   ],
   "source": [
    "gridsearch_batch(CountVectorizer(), MultinomialNB(), param_dict, model_outcomes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Performance Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Transformer</th>\n",
       "      <th>Estimator</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>Best Parameters</th>\n",
       "      <th>Best Score</th>\n",
       "      <th>Training Score</th>\n",
       "      <th>Test Score</th>\n",
       "      <th>Discrepancy</th>\n",
       "      <th>Runtime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>df_params</td>\n",
       "      <td>{'vec__max_df': 0.6, 'vec__min_df': 0.1, 'vec_...</td>\n",
       "      <td>0.946823</td>\n",
       "      <td>0.985497</td>\n",
       "      <td>0.943639</td>\n",
       "      <td>0.041858</td>\n",
       "      <td>9m 19s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>features_params</td>\n",
       "      <td>{'vec__max_features': 500, 'vec__ngram_range':...</td>\n",
       "      <td>0.943370</td>\n",
       "      <td>0.990331</td>\n",
       "      <td>0.948470</td>\n",
       "      <td>0.041861</td>\n",
       "      <td>4m 3s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>limited_all_params</td>\n",
       "      <td>{'vec__max_df': 0.8, 'vec__max_features': 300,...</td>\n",
       "      <td>0.941298</td>\n",
       "      <td>0.986188</td>\n",
       "      <td>0.940419</td>\n",
       "      <td>0.045769</td>\n",
       "      <td>3m 26s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>features_params</td>\n",
       "      <td>{'vec__max_features': 300, 'vec__ngram_range':...</td>\n",
       "      <td>0.914365</td>\n",
       "      <td>0.938536</td>\n",
       "      <td>0.916264</td>\n",
       "      <td>0.022272</td>\n",
       "      <td>3m 55s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>df_params</td>\n",
       "      <td>{'vec__max_df': 0.6, 'vec__min_df': 0.1, 'vec_...</td>\n",
       "      <td>0.903315</td>\n",
       "      <td>0.933011</td>\n",
       "      <td>0.911433</td>\n",
       "      <td>0.021578</td>\n",
       "      <td>9m 26s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>limited_all_params</td>\n",
       "      <td>{'vec__max_df': 0.7, 'vec__max_features': 300,...</td>\n",
       "      <td>0.903315</td>\n",
       "      <td>0.934392</td>\n",
       "      <td>0.914654</td>\n",
       "      <td>0.019738</td>\n",
       "      <td>3m 22s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>features_params</td>\n",
       "      <td>{'vec__max_features': 900, 'vec__ngram_range':...</td>\n",
       "      <td>0.901934</td>\n",
       "      <td>0.924724</td>\n",
       "      <td>0.906602</td>\n",
       "      <td>0.018122</td>\n",
       "      <td>3m 46s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>df_params</td>\n",
       "      <td>{'vec__max_df': 0.6, 'vec__min_df': 0.1, 'vec_...</td>\n",
       "      <td>0.888122</td>\n",
       "      <td>0.893646</td>\n",
       "      <td>0.884058</td>\n",
       "      <td>0.009588</td>\n",
       "      <td>8m 59s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>CountVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>limited_all_params</td>\n",
       "      <td>{'vec__max_df': 0.7, 'vec__max_features': 300,...</td>\n",
       "      <td>0.884669</td>\n",
       "      <td>0.895718</td>\n",
       "      <td>0.887279</td>\n",
       "      <td>0.008440</td>\n",
       "      <td>3m 3s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>features_params</td>\n",
       "      <td>{'vec__max_features': 900, 'vec__ngram_range':...</td>\n",
       "      <td>0.882597</td>\n",
       "      <td>0.916436</td>\n",
       "      <td>0.890499</td>\n",
       "      <td>0.025937</td>\n",
       "      <td>3m 27s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>df_params</td>\n",
       "      <td>{'vec__max_df': 0.6, 'vec__min_df': 0.1, 'vec_...</td>\n",
       "      <td>0.861188</td>\n",
       "      <td>0.883978</td>\n",
       "      <td>0.848631</td>\n",
       "      <td>0.035347</td>\n",
       "      <td>8m 59s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>TfidfVectorizer(analyzer='word', binary=False,...</td>\n",
       "      <td>MultinomialNB(alpha=1.0, class_prior=None, fit...</td>\n",
       "      <td>limited_all_params</td>\n",
       "      <td>{'vec__max_df': 0.7, 'vec__max_features': 700,...</td>\n",
       "      <td>0.857735</td>\n",
       "      <td>0.883287</td>\n",
       "      <td>0.850242</td>\n",
       "      <td>0.033046</td>\n",
       "      <td>3m 0s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Transformer  \\\n",
       "0   CountVectorizer(analyzer='word', binary=False,...   \n",
       "1   CountVectorizer(analyzer='word', binary=False,...   \n",
       "2   CountVectorizer(analyzer='word', binary=False,...   \n",
       "3   TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "4   TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "5   TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "6   CountVectorizer(analyzer='word', binary=False,...   \n",
       "7   CountVectorizer(analyzer='word', binary=False,...   \n",
       "8   CountVectorizer(analyzer='word', binary=False,...   \n",
       "9   TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "10  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "11  TfidfVectorizer(analyzer='word', binary=False,...   \n",
       "\n",
       "                                            Estimator          Parameters  \\\n",
       "0   LogisticRegression(C=1.0, class_weight=None, d...           df_params   \n",
       "1   LogisticRegression(C=1.0, class_weight=None, d...     features_params   \n",
       "2   LogisticRegression(C=1.0, class_weight=None, d...  limited_all_params   \n",
       "3   LogisticRegression(C=1.0, class_weight=None, d...     features_params   \n",
       "4   LogisticRegression(C=1.0, class_weight=None, d...           df_params   \n",
       "5   LogisticRegression(C=1.0, class_weight=None, d...  limited_all_params   \n",
       "6   MultinomialNB(alpha=1.0, class_prior=None, fit...     features_params   \n",
       "7   MultinomialNB(alpha=1.0, class_prior=None, fit...           df_params   \n",
       "8   MultinomialNB(alpha=1.0, class_prior=None, fit...  limited_all_params   \n",
       "9   MultinomialNB(alpha=1.0, class_prior=None, fit...     features_params   \n",
       "10  MultinomialNB(alpha=1.0, class_prior=None, fit...           df_params   \n",
       "11  MultinomialNB(alpha=1.0, class_prior=None, fit...  limited_all_params   \n",
       "\n",
       "                                      Best Parameters  Best Score  \\\n",
       "0   {'vec__max_df': 0.6, 'vec__min_df': 0.1, 'vec_...    0.946823   \n",
       "1   {'vec__max_features': 500, 'vec__ngram_range':...    0.943370   \n",
       "2   {'vec__max_df': 0.8, 'vec__max_features': 300,...    0.941298   \n",
       "3   {'vec__max_features': 300, 'vec__ngram_range':...    0.914365   \n",
       "4   {'vec__max_df': 0.6, 'vec__min_df': 0.1, 'vec_...    0.903315   \n",
       "5   {'vec__max_df': 0.7, 'vec__max_features': 300,...    0.903315   \n",
       "6   {'vec__max_features': 900, 'vec__ngram_range':...    0.901934   \n",
       "7   {'vec__max_df': 0.6, 'vec__min_df': 0.1, 'vec_...    0.888122   \n",
       "8   {'vec__max_df': 0.7, 'vec__max_features': 300,...    0.884669   \n",
       "9   {'vec__max_features': 900, 'vec__ngram_range':...    0.882597   \n",
       "10  {'vec__max_df': 0.6, 'vec__min_df': 0.1, 'vec_...    0.861188   \n",
       "11  {'vec__max_df': 0.7, 'vec__max_features': 700,...    0.857735   \n",
       "\n",
       "    Training Score  Test Score  Discrepancy Runtime  \n",
       "0         0.985497    0.943639     0.041858  9m 19s  \n",
       "1         0.990331    0.948470     0.041861   4m 3s  \n",
       "2         0.986188    0.940419     0.045769  3m 26s  \n",
       "3         0.938536    0.916264     0.022272  3m 55s  \n",
       "4         0.933011    0.911433     0.021578  9m 26s  \n",
       "5         0.934392    0.914654     0.019738  3m 22s  \n",
       "6         0.924724    0.906602     0.018122  3m 46s  \n",
       "7         0.893646    0.884058     0.009588  8m 59s  \n",
       "8         0.895718    0.887279     0.008440   3m 3s  \n",
       "9         0.916436    0.890499     0.025937  3m 27s  \n",
       "10        0.883978    0.848631     0.035347  8m 59s  \n",
       "11        0.883287    0.850242     0.033046   3m 0s  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes = pd.DataFrame(model_outcomes)\n",
    "\n",
    "outcomes.sort_values(by = \"Best Score\", ascending = False, inplace = True)\n",
    "\n",
    "outcomes.reset_index(inplace = True)\n",
    "\n",
    "outcomes.drop(columns = [\"index\"], inplace = True)\n",
    "\n",
    "outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vec__max_features': 300,\n",
       " 'vec__ngram_range': (1, 2),\n",
       " 'vec__stop_words': 'english'}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pulling best parameters for the model that yielded a high accuracy score (91%) with a smaller discrepancy (2.2%)\n",
    "\n",
    "outcomes[\"Best Parameters\"][3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'vec__max_df': 0.6,\n",
       " 'vec__min_df': 0.1,\n",
       " 'vec__ngram_range': (1, 1),\n",
       " 'vec__stop_words': 'english'}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outcomes[\"Best Parameters\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Final Model \n",
    "\n",
    "The final model for this project is a Logistic Regression model with transformation done by TFIDFVectorizer. This model yielded one of the highest accuracy scores, and though other models had higher accuracy scores they also had a wider range in accuracy scores between the training and test datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vec',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=300,\n",
       "                                 min_df=1, ngram_range=(1, 2), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=None, use_idf=True,\n",
       "                                 vocabulary=None)),\n",
       "                ('lr',\n",
       "                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n",
       "                                    fit_intercept=True, intercept_scaling=1,\n",
       "                                    l1_ratio=None, max_iter=100,\n",
       "                                    multi_class='warn', n_jobs=None,\n",
       "                                    penalty='l2', random_state=None,\n",
       "                                    solver='liblinear', tol=0.0001, verbose=0,\n",
       "                                    warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "                (\"vec\", TfidfVectorizer(max_features = 300, \n",
    "                                        ngram_range = (1, 2), \n",
    "                                        stop_words = \"english\")),\n",
    "                (\"lr\", LogisticRegression(solver = \"liblinear\"))\n",
    "            ])\n",
    "\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93853591160221"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9162640901771336"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
